{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "train = pd.read_csv(\"spooky-authors/train.zip\", index_col=['id'])\n",
    "test = pd.read_csv(\"spooky-authors/test.zip\", index_col=['id'])\n",
    "sample_submission = pd.read_csv(\"spooky-authors/sample_submission.zip\", index_col=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Първо събирам train и test сетовете. По този начин ако има думи, които ги има само в теста CountVectorizer създаде колони за тях и в трейна. Когато тренирам модел ще ползвам само редовете от които идват от train сета."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combo = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19579, 2)\n",
      "(8392, 1)\n",
      "(27971, 2)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)\n",
    "print(combo.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Идеята е да ползвам LDA, за да открия n на брой теми. С малко късмет различните автори ще са писали по различни теми и това ще помогне за тяхното идентифициране."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Използвам LDA с 20 теми (няма смисъл от повече, резултата не се променя особено)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27971, 20)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from scipy.sparse import coo_matrix, hstack\n",
    "\n",
    "vectorizer = CountVectorizer(max_df=.15, max_features=10000)\n",
    "X = vectorizer.fit_transform(combo.text)\n",
    "lda = LatentDirichletAllocation(n_components=20, \n",
    "                                learning_method=\"batch\", max_iter=15, random_state=0)\n",
    "topics = lda.fit_transform(X)\n",
    "topics.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Създавам си функции, които да извличат темите от техта и да го векторизират с TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize_text(text):\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1, 2), min_df=2,\n",
    "                                 max_df=0.8, lowercase=False)\n",
    "    return tfidf.fit_transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_topics(text, lda):\n",
    "    vectorizer = CountVectorizer(max_df=.15, max_features=10000)\n",
    "    vec = vectorizer.fit_transform(text)\n",
    "    return lda.transform(vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Събирам двете sparse матрици в една."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_topics_and_vectors(vectors, topics):\n",
    "    sparse_topics = coo_matrix(topics)\n",
    "    return hstack([vectors, sparse_topics])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прилагам всичките операции чрез transform_text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform_text(text, lda):\n",
    "    vector = vectorize_text(text)\n",
    "    topics = generate_topics(text, lda)\n",
    "    return combine_topics_and_vectors(vector, topics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Първо пробвам да предрека автора само с генерираните теми. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40349265  0.40346307  0.4035249 ]\n",
      "[-1.08185797 -1.08186615 -1.08166839]\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.01)\n",
    "text = generate_topics(combo[:19579].text, lda)\n",
    "print(cross_val_score(model, text, train.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(model, text, train.author,cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не се получи особено добре. Изглежда авторите не използват толкова различни теми (все пак всички са spooky :D)\n",
    "\n",
    "Пробвам само с Tfidf векторизиран текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.84987745  0.84400858  0.84061303]\n",
      "[-0.39747551 -0.39623287 -0.4030639 ]\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.01)\n",
    "text = vectorize_text(combo[:19579].text)\n",
    "print(cross_val_score(model, text, train.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(model, text, train.author,cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Това вече е по-добър резултат от този на лекции. Изглежда комбинирането на двата файла оказва влияние.\n",
    "\n",
    "Да проверим все пак като се ползват и двете дали ще има полза."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8504902   0.84462151  0.8410728 ]\n",
      "[-0.39707522 -0.39583773 -0.40274484]\n"
     ]
    }
   ],
   "source": [
    "model = MultinomialNB(alpha=0.01)\n",
    "text = transform_text(combo[:19579].text, lda)\n",
    "print(cross_val_score(model, text, train.author, cv=3, n_jobs=3))\n",
    "print(cross_val_score(model, text, train.author, cv=3, n_jobs=3, \n",
    "                      scoring='neg_log_loss'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резултатите се подобриха съвсем минимално, но все пак се подобриха."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combo_vec = transform_text(combo.text, lda).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = MultinomialNB(alpha=0.01)\n",
    "train_vec = combo_vec[:19579, :]\n",
    "test_vec = combo_vec[19579:, :]\n",
    "model.fit(train_vec, train.author)\n",
    "test_predictions = model.predict_proba(test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submit_file = pd.DataFrame(test_predictions, columns=['EAP', 'HPL', 'MWS'], index=test.index)\n",
    "submit_file.head(10)\n",
    "submit_file.to_csv(\"~/Desktop/spooky_prediction.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резултата в kaggle e :\n",
    "<img src=\"img/spooky_kaggle.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резултата без LDA в kaggle беше малко по нисък - 0.369.... така, че LDA все пак помогна малко.\n",
    "\n",
    "Също пробвах с LogisticRegression, SVC, RandomForest с много различни параметри, но винаги бяха значително по-слаби от Бейс, затова не ги включих в тетрадката."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
